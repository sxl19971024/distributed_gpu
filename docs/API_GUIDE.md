# API ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜æ¡†æ¶ä¸­æ¯ä¸ªåˆ†å¸ƒå¼ç®—æ³•çš„ä½¿ç”¨æ–¹æ³•ã€å‚æ•°å’Œç¤ºä¾‹ã€‚

## ğŸ“‹ ç›®å½•

1. [åˆå§‹åŒ–æ¡†æ¶](#åˆå§‹åŒ–æ¡†æ¶)
2. [çŸ©é˜µè¿ç®—](#çŸ©é˜µè¿ç®—)
3. [å·ç§¯æ“ä½œ](#å·ç§¯æ“ä½œ)
4. [å‚…é‡Œå¶å˜æ¢](#å‚…é‡Œå¶å˜æ¢)
5. [Einsteinæ±‚å’Œ](#einsteinæ±‚å’Œ)
6. [å½’çº¦æ“ä½œ](#å½’çº¦æ“ä½œ)
7. [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)

---

## åˆå§‹åŒ–æ¡†æ¶

åœ¨ä½¿ç”¨ä»»ä½•åˆ†å¸ƒå¼ç®—æ³•ä¹‹å‰ï¼Œå¿…é¡»å…ˆåˆå§‹åŒ– MPI ç¯å¢ƒå’Œå¼ é‡åˆ†é…å™¨ã€‚

```python
import torch
from src.mpi_manager import MPIManager
from src.tensor_distributor import TensorDistributor

# åˆå§‹åŒ–ï¼ˆæ‰€æœ‰è¿›ç¨‹éƒ½å¿…é¡»æ‰§è¡Œï¼‰
mpi = MPIManager()
distributor = TensorDistributor(mpi)

# è·å–å½“å‰è¿›ç¨‹ä¿¡æ¯
print(f"è¿›ç¨‹ {mpi.get_rank()}/{mpi.get_size()}, GPU {mpi.get_gpu_id()}")
```

**é‡è¦åŸåˆ™**ï¼š
- âš ï¸ æ‰€æœ‰è¿›ç¨‹éƒ½å¿…é¡»è°ƒç”¨ç›¸åŒçš„åˆ†å¸ƒå¼å‡½æ•°
- âš ï¸ è¾“å…¥æ•°æ®ä»…åœ¨ä¸»è¿›ç¨‹ï¼ˆrank=0ï¼‰æä¾›ï¼Œå…¶ä»–è¿›ç¨‹ä¼  `None`
- âš ï¸ è¾“å‡ºç»“æœä»…ä¸»è¿›ç¨‹è¿”å›æœ‰æ•ˆå€¼ï¼Œå…¶ä»–è¿›ç¨‹è¿”å› `None`

---

## çŸ©é˜µè¿ç®—

### 1. distributed_matmul - çŸ©é˜µä¹˜æ³•

**åŠŸèƒ½**ï¼šè®¡ç®— C = A @ B

```python
from src.algorithms.matrix_ops import distributed_matmul

# å‚æ•°è¯´æ˜
C = distributed_matmul(
    A,              # torch.Tensor: çŸ©é˜µA [M, K]ï¼Œä»…ä¸»è¿›ç¨‹æä¾›
    B,              # torch.Tensor: çŸ©é˜µB [K, N]ï¼Œä»…ä¸»è¿›ç¨‹æä¾›
    mpi,            # MPIManager: MPIç®¡ç†å™¨
    distributor     # TensorDistributor: å¼ é‡åˆ†é…å™¨
)
# è¿”å›: torch.Tensor [M, N]ï¼Œä»…ä¸»è¿›ç¨‹è¿”å›æœ‰æ•ˆç»“æœ
```

**å®Œæ•´ç¤ºä¾‹**ï¼š
```python
import torch
from src.mpi_manager import MPIManager
from src.tensor_distributor import TensorDistributor
from src.algorithms.matrix_ops import distributed_matmul

mpi = MPIManager()
distributor = TensorDistributor(mpi)

# ä¸»è¿›ç¨‹åˆ›å»ºæ•°æ®
if mpi.is_master_process():
    A = torch.randn(5000, 3000).cuda()  # [M, K]
    B = torch.randn(3000, 4000).cuda()  # [K, N]
else:
    A, B = None, None

# æ‰€æœ‰è¿›ç¨‹è°ƒç”¨ï¼ˆé‡è¦ï¼ï¼‰
C = distributed_matmul(A, B, mpi, distributor)

# ä¸»è¿›ç¨‹å¤„ç†ç»“æœ
if mpi.is_master_process():
    print(f"ç»“æœå½¢çŠ¶: {C.shape}")  # [5000, 4000]
```

**è¿è¡Œå‘½ä»¤**ï¼š
```bash
mpirun -n 4 python your_script.py
```

---

### 2. distributed_batch_matmul - æ‰¹é‡çŸ©é˜µä¹˜æ³•

**åŠŸèƒ½**ï¼šè®¡ç®—æ‰¹é‡çŸ©é˜µä¹˜æ³• C = A @ B

```python
from src.algorithms.matrix_ops import distributed_batch_matmul

C = distributed_batch_matmul(
    A,              # torch.Tensor: [batch, M, K]
    B,              # torch.Tensor: [batch, K, N] æˆ– [K, N]
    mpi,            # MPIManager
    distributor     # TensorDistributor
)
# è¿”å›: torch.Tensor [batch, M, N]
```

**ç¤ºä¾‹**ï¼š
```python
if mpi.is_master_process():
    A = torch.randn(64, 256, 128).cuda()  # [batch, M, K]
    B = torch.randn(64, 128, 256).cuda()  # [batch, K, N]
else:
    A, B = None, None

C = distributed_batch_matmul(A, B, mpi, distributor)
# C.shape = [64, 256, 256]
```

---

### 3. distributed_transpose - çŸ©é˜µè½¬ç½®

```python
from src.algorithms.matrix_ops import distributed_transpose

A_T = distributed_transpose(
    A,              # torch.Tensor: è¾“å…¥çŸ©é˜µ
    mpi,            # MPIManager
    distributor,    # TensorDistributor
    dim0=0,         # int: ç¬¬ä¸€ä¸ªäº¤æ¢ç»´åº¦ï¼ˆé»˜è®¤0ï¼‰
    dim1=1          # int: ç¬¬äºŒä¸ªäº¤æ¢ç»´åº¦ï¼ˆé»˜è®¤1ï¼‰
)
```

---

### 4. distributed_add - å¼ é‡åŠ æ³•

```python
from src.algorithms.matrix_ops import distributed_add

C = distributed_add(
    A,              # torch.Tensor: å¼ é‡A
    B,              # torch.Tensor: å¼ é‡Bï¼ˆå½¢çŠ¶ä¸Aç›¸åŒï¼‰
    mpi,            # MPIManager
    distributor     # TensorDistributor
)
# è¿”å›: C = A + B
```

---

## å·ç§¯æ“ä½œ

### 1. distributed_conv2d - 2Då·ç§¯

**åŠŸèƒ½**ï¼šåˆ†å¸ƒå¼2Då·ç§¯ï¼ŒæŒ‰batchç»´åº¦åˆ†å‰²

```python
from src.algorithms.convolution import distributed_conv2d

output = distributed_conv2d(
    input,          # torch.Tensor: [N, C_in, H, W] è¾“å…¥
    weight,         # torch.Tensor: [C_out, C_in, kH, kW] å·ç§¯æ ¸
    mpi,            # MPIManager
    distributor,    # TensorDistributor
    bias=None,      # torch.Tensor: [C_out] åç½®ï¼ˆå¯é€‰ï¼‰
    stride=(1, 1),  # tuple: æ­¥é•¿
    padding=(0, 0), # tuple: å¡«å……
    dilation=(1, 1),# tuple: è†¨èƒ€ç‡
    groups=1        # int: åˆ†ç»„æ•°
)
# è¿”å›: torch.Tensor [N, C_out, H_out, W_out]
```

**å®Œæ•´ç¤ºä¾‹**ï¼š
```python
from src.algorithms.convolution import distributed_conv2d

if mpi.is_master_process():
    # è¾“å…¥: batch=32, channels=64, height=128, width=128
    input = torch.randn(32, 64, 128, 128).cuda()
    # å·ç§¯æ ¸: out_channels=128, in_channels=64, kernel=3x3
    weight = torch.randn(128, 64, 3, 3).cuda()
    bias = torch.randn(128).cuda()
else:
    input, weight, bias = None, None, None

output = distributed_conv2d(
    input, weight, mpi, distributor,
    bias=bias,
    stride=(1, 1),
    padding=(1, 1)  # same padding
)

if mpi.is_master_process():
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")  # [32, 128, 128, 128]
```

---

### 2. distributed_conv3d - 3Då·ç§¯

```python
from src.algorithms.convolution import distributed_conv3d

output = distributed_conv3d(
    input,          # torch.Tensor: [N, C_in, D, H, W]
    weight,         # torch.Tensor: [C_out, C_in, kD, kH, kW]
    mpi,
    distributor,
    bias=None,
    stride=(1, 1, 1),
    padding=(0, 0, 0),
    dilation=(1, 1, 1),
    groups=1
)
```

---

## å‚…é‡Œå¶å˜æ¢

### 1. distributed_fft - 1D FFT

```python
from src.algorithms.fft import distributed_fft

output = distributed_fft(
    input,          # torch.Tensor: è¾“å…¥å¼ é‡
    mpi,            # MPIManager
    distributor,    # TensorDistributor
    n=None,         # int: FFTé•¿åº¦ï¼ˆNoneä½¿ç”¨è¾“å…¥é•¿åº¦ï¼‰
    dim=-1,         # int: FFTç»´åº¦ï¼ˆé»˜è®¤æœ€åä¸€ç»´ï¼‰
    norm="backward" # str: å½’ä¸€åŒ–æ¨¡å¼ ("backward", "ortho", "forward")
)
```

**ç¤ºä¾‹**ï¼š
```python
from src.algorithms.fft import distributed_fft

if mpi.is_master_process():
    # 64ä¸ªä¿¡å·ï¼Œæ¯ä¸ª1024ä¸ªé‡‡æ ·ç‚¹
    signal = torch.randn(64, 1024).cuda()
else:
    signal = None

spectrum = distributed_fft(signal, mpi, distributor)

if mpi.is_master_process():
    print(f"é¢‘è°±å½¢çŠ¶: {spectrum.shape}")  # [64, 1024]
```

---

### 2. distributed_ifft - é€†FFT

```python
from src.algorithms.fft import distributed_ifft

output = distributed_ifft(
    input,          # torch.Tensor: é¢‘åŸŸä¿¡å·
    mpi,
    distributor,
    n=None,
    dim=-1,
    norm="backward"
)
```

---

### 3. distributed_fft2d - 2D FFT

```python
from src.algorithms.fft import distributed_fft2d

output = distributed_fft2d(
    input,          # torch.Tensor: [..., H, W]
    mpi,
    distributor,
    s=None,         # tuple: FFTå¤§å° (H, W)
    dim=(-2, -1),   # tuple: FFTç»´åº¦
    norm="backward"
)
```

**ç¤ºä¾‹**ï¼ˆå›¾åƒé¢‘è°±åˆ†æï¼‰ï¼š
```python
from src.algorithms.fft import distributed_fft2d

if mpi.is_master_process():
    # 32å¼  256x256 çš„å›¾åƒ
    images = torch.randn(32, 256, 256).cuda()
else:
    images = None

spectrum = distributed_fft2d(images, mpi, distributor)

if mpi.is_master_process():
    print(f"é¢‘è°±å½¢çŠ¶: {spectrum.shape}")  # [32, 256, 256]
```

---

### 4. distributed_rfft - å®æ•°FFT

```python
from src.algorithms.fft import distributed_rfft

output = distributed_rfft(
    input,          # torch.Tensor: å®æ•°è¾“å…¥
    mpi,
    distributor,
    n=None,
    dim=-1,
    norm="backward"
)
# è¿”å›: åªæœ‰æ­£é¢‘ç‡éƒ¨åˆ†ï¼Œæ›´é«˜æ•ˆ
```

---

## Einsteinæ±‚å’Œ

### 1. distributed_einsum - Einsteinæ±‚å’Œï¼ˆé›†æˆopt_einsumï¼‰

**åŠŸèƒ½**ï¼šé€šç”¨å¼ é‡æ”¶ç¼©ï¼Œæ”¯æŒæœ€ä¼˜è·¯å¾„ä¼˜åŒ–

```python
from src.algorithms.einsum import distributed_einsum

result = distributed_einsum(
    equation,       # str: Einsteinæ±‚å’Œè¡¨è¾¾å¼
    *operands,      # torch.Tensor: æ“ä½œæ•°ï¼ˆå¯å˜å‚æ•°ï¼‰
    mpi=mpi,        # MPIManager
    distributor=distributor,  # TensorDistributor
    optimize='auto',# str: ä¼˜åŒ–ç­–ç•¥ ('optimal', 'dp', 'greedy', 'auto')
    use_opt_einsum=True  # bool: æ˜¯å¦ä½¿ç”¨opt_einsumä¼˜åŒ–
)
```

**å¸¸ç”¨è¡¨è¾¾å¼**ï¼š

| è¡¨è¾¾å¼ | æ“ä½œ | ç¤ºä¾‹å½¢çŠ¶ |
|--------|------|----------|
| `'ij,jk->ik'` | çŸ©é˜µä¹˜æ³• | [M,K] @ [K,N] |
| `'bij,bjk->bik'` | æ‰¹é‡çŸ©é˜µä¹˜æ³• | [B,M,K] @ [B,K,N] |
| `'ii->'` | çŸ©é˜µçš„è¿¹ | [N,N] â†’ æ ‡é‡ |
| `'ij->ji'` | è½¬ç½® | [M,N] â†’ [N,M] |
| `'i,j->ij'` | å¤–ç§¯ | [M], [N] â†’ [M,N] |
| `'ijk,ikl->ijl'` | å¼ é‡æ”¶ç¼© | è‡ªå®šä¹‰ |

**ç¤ºä¾‹**ï¼š
```python
from src.algorithms.einsum import distributed_einsum

if mpi.is_master_process():
    A = torch.randn(32, 128, 64).cuda()
    B = torch.randn(32, 64, 256).cuda()
else:
    A, B = None, None

# æ‰¹é‡çŸ©é˜µä¹˜æ³•
C = distributed_einsum('bij,bjk->bik', A, B, mpi=mpi, distributor=distributor)

if mpi.is_master_process():
    print(f"ç»“æœå½¢çŠ¶: {C.shape}")  # [32, 128, 256]
```

---

### 2. æŸ¥çœ‹æœ€ä¼˜æ”¶ç¼©è·¯å¾„

```python
from src.algorithms.einsum import print_path_info, compare_optimization_strategies

# æ‰“å°æœ€ä¼˜è·¯å¾„ä¿¡æ¯
print_path_info('ij,jk,kl,lm->im', (100,50), (50,80), (80,60), (60,40))

# æ¯”è¾ƒä¸åŒä¼˜åŒ–ç­–ç•¥
compare_optimization_strategies('ij,jk,kl->il', (100,50), (50,80), (80,40))
```

---

### 3. distributed_tensordot - å¼ é‡ç‚¹ç§¯

```python
from src.algorithms.einsum import distributed_tensordot

result = distributed_tensordot(
    a,              # torch.Tensor: ç¬¬ä¸€ä¸ªå¼ é‡
    b,              # torch.Tensor: ç¬¬äºŒä¸ªå¼ é‡
    dims,           # int: æ”¶ç¼©çš„ç»´åº¦æ•°
    mpi,
    distributor
)
```

---

## å½’çº¦æ“ä½œ

### 1. distributed_sum - æ±‚å’Œ

```python
from src.algorithms.reduction import distributed_sum

result = distributed_sum(
    tensor,         # torch.Tensor: è¾“å…¥å¼ é‡
    mpi,            # MPIManager
    distributor,    # TensorDistributor
    dim=None,       # int: æ±‚å’Œç»´åº¦ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨æ±‚å’Œï¼‰
    keepdim=False   # bool: æ˜¯å¦ä¿æŒç»´åº¦
)
```

**ç¤ºä¾‹**ï¼š
```python
from src.algorithms.reduction import distributed_sum

if mpi.is_master_process():
    x = torch.randn(1000, 1000).cuda()
else:
    x = None

# å…¨å±€æ±‚å’Œ
total = distributed_sum(x, mpi, distributor, dim=None)

# æŒ‰ç»´åº¦æ±‚å’Œ
row_sum = distributed_sum(x, mpi, distributor, dim=1)  # [1000]
col_sum = distributed_sum(x, mpi, distributor, dim=0)  # [1000]
```

---

### 2. distributed_mean - å‡å€¼

```python
from src.algorithms.reduction import distributed_mean

result = distributed_mean(
    tensor,
    mpi,
    distributor,
    dim=None,       # int: æ±‚å‡å€¼ç»´åº¦
    keepdim=False
)
```

---

### 3. distributed_max - æœ€å¤§å€¼

```python
from src.algorithms.reduction import distributed_max

result = distributed_max(
    tensor,
    mpi,
    distributor,
    dim=None,       # int: æ±‚æœ€å¤§å€¼ç»´åº¦
    keepdim=False
)
```

---

### 4. distributed_min - æœ€å°å€¼

```python
from src.algorithms.reduction import distributed_min

result = distributed_min(
    tensor,
    mpi,
    distributor,
    dim=None,
    keepdim=False
)
```

---

## é«˜çº§åŠŸèƒ½

### 1. ä»£ä»·æ¨¡å‹åˆ†æ

```python
from src.cost_model import CostModel, ClusterConfig

# è‡ªåŠ¨æ£€æµ‹é›†ç¾¤é…ç½®
config = ClusterConfig.from_auto_detect(num_nodes=4)

# åˆ›å»ºä»£ä»·æ¨¡å‹
cost_model = CostModel(config)

# åˆ†æçŸ©é˜µä¹˜æ³•ä»£ä»·
cost_model.print_analysis(M=5000, K=5000, N=5000)

# è·å–æœ€ä¼˜åˆ†å‰²ç­–ç•¥
plan = cost_model.find_optimal_strategy(M=5000, K=5000, N=5000)
print(f"æ¨èç­–ç•¥: {plan.strategy}")
print(f"é¢„ä¼°åŠ é€Ÿæ¯”: {plan.cost.speedup:.2f}x")
```

---

### 2. æ€§èƒ½åˆ†æ

```python
from src.utils.profiler import Profiler

profiler = Profiler(enabled=mpi.is_master_process())

profiler.start("matmul")
C = distributed_matmul(A, B, mpi, distributor)
profiler.end("matmul")

profiler.print_summary()
```

---

### 3. GPU ç®¡ç†

```python
from src.gpu_manager import GPUManager

gpu = GPUManager(mpi.get_gpu_id())

# æ‰“å° GPU ä¿¡æ¯
gpu.print_info()

# æŸ¥çœ‹æ˜¾å­˜ä½¿ç”¨
gpu.print_memory_info()

# æ£€æŸ¥æ˜¯å¦èƒ½æ”¾ä¸‹å¼ é‡
can_fit = gpu.can_fit((10000, 10000), (10000, 10000), dtype=torch.float32)
```

---

## å®Œæ•´ç¤ºä¾‹è„šæœ¬

```python
#!/usr/bin/env python
"""
å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
è¿è¡Œ: mpirun -n 4 python example.py
"""
import torch
from src.mpi_manager import MPIManager
from src.tensor_distributor import TensorDistributor
from src.gpu_manager import GPUManager
from src.algorithms.matrix_ops import distributed_matmul
from src.algorithms.convolution import distributed_conv2d
from src.algorithms.fft import distributed_fft2d
from src.algorithms.einsum import distributed_einsum
from src.algorithms.reduction import distributed_mean

def main():
    # åˆå§‹åŒ–
    mpi = MPIManager()
    distributor = TensorDistributor(mpi)
    gpu = GPUManager(mpi.get_gpu_id())
    
    if mpi.is_master_process():
        print("=" * 50)
        print("åˆ†å¸ƒå¼GPUè®¡ç®—æ¡†æ¶ä½¿ç”¨ç¤ºä¾‹")
        print("=" * 50)
        gpu.print_info()
    
    # ========== 1. çŸ©é˜µä¹˜æ³• ==========
    if mpi.is_master_process():
        print("\n[1] çŸ©é˜µä¹˜æ³•")
        A = torch.randn(2000, 1500).cuda()
        B = torch.randn(1500, 1000).cuda()
    else:
        A, B = None, None
    
    C = distributed_matmul(A, B, mpi, distributor)
    
    if mpi.is_master_process():
        print(f"    {A.shape} @ {B.shape} = {C.shape}")
    
    # ========== 2. å·ç§¯ ==========
    if mpi.is_master_process():
        print("\n[2] 2Då·ç§¯")
        x = torch.randn(16, 32, 64, 64).cuda()
        w = torch.randn(64, 32, 3, 3).cuda()
    else:
        x, w = None, None
    
    y = distributed_conv2d(x, w, mpi, distributor, padding=(1, 1))
    
    if mpi.is_master_process():
        print(f"    è¾“å…¥: {x.shape}, å·ç§¯æ ¸: {w.shape}, è¾“å‡º: {y.shape}")
    
    # ========== 3. FFT ==========
    if mpi.is_master_process():
        print("\n[3] 2D FFT")
        img = torch.randn(8, 128, 128).cuda()
    else:
        img = None
    
    spec = distributed_fft2d(img, mpi, distributor)
    
    if mpi.is_master_process():
        print(f"    è¾“å…¥: {img.shape}, é¢‘è°±: {spec.shape}")
    
    # ========== 4. Einsum ==========
    if mpi.is_master_process():
        print("\n[4] Einsteinæ±‚å’Œ")
        P = torch.randn(16, 64, 32).cuda()
        Q = torch.randn(16, 32, 64).cuda()
    else:
        P, Q = None, None
    
    R = distributed_einsum('bij,bjk->bik', P, Q, mpi=mpi, distributor=distributor)
    
    if mpi.is_master_process():
        print(f"    'bij,bjk->bik': {P.shape}, {Q.shape} -> {R.shape}")
    
    # ========== 5. å½’çº¦ ==========
    if mpi.is_master_process():
        print("\n[5] å½’çº¦æ“ä½œ")
        data = torch.randn(100, 100, 100).cuda()
    else:
        data = None
    
    avg = distributed_mean(data, mpi, distributor)
    
    if mpi.is_master_process():
        print(f"    å‡å€¼: {avg.item():.6f}")
    
    # å®Œæˆ
    if mpi.is_master_process():
        print("\n" + "=" * 50)
        print("æ‰€æœ‰æ“ä½œå®Œæˆï¼")
        gpu.print_memory_info()

if __name__ == "__main__":
    main()
```

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆå…¶ä»–è¿›ç¨‹è¦ä¼  Noneï¼Ÿ
å› ä¸ºæ•°æ®åªåœ¨ä¸»è¿›ç¨‹å­˜åœ¨ï¼Œåˆ†å¸ƒå¼å‡½æ•°å†…éƒ¨ä¼šè‡ªåŠ¨å°†æ•°æ®åˆ†å‘åˆ°å…¶ä»–è¿›ç¨‹ã€‚

### Q2: ä¸ºä»€ä¹ˆæ‰€æœ‰è¿›ç¨‹éƒ½è¦è°ƒç”¨å‡½æ•°ï¼Ÿ
MPI çš„é›†åˆé€šä¿¡è¦æ±‚æ‰€æœ‰è¿›ç¨‹éƒ½å‚ä¸ï¼Œå¦åˆ™ä¼šæ­»é”ã€‚

### Q3: å¦‚ä½•å¤„ç†è¿”å›çš„ Noneï¼Ÿ
```python
result = distributed_matmul(A, B, mpi, distributor)
if mpi.is_master_process():
    # åªæœ‰ä¸»è¿›ç¨‹å¤„ç†ç»“æœ
    save(result)
```

### Q4: å¦‚ä½•è°ƒæ•´ GPU æ•°é‡ï¼Ÿ
ä¿®æ”¹ `mpirun -n <æ•°é‡>` å‚æ•°å³å¯ã€‚

---

## è”ç³»æ–¹å¼

- ä½œè€…: å­™å°æ—
- Email: 1271364457@qq.com
- GitHub: https://github.com/sxl19971024/distributed_gpu
