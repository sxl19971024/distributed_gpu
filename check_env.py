#!/usr/bin/env python3
"""
ç¯å¢ƒæ£€æµ‹è„šæœ¬ - éªŒè¯ distributed_gpu æ¡†æ¶å®‰è£…æ˜¯å¦æˆåŠŸ
ç›®æ ‡ç¯å¢ƒ: OpenMPI 4.1.5 + CUDA 12.1

ä½¿ç”¨æ–¹å¼: python check_env.py
"""

from __future__ import annotations

import os
import re
import shutil
import subprocess
import sys
from typing import Callable, Optional, Tuple


# ==================== è¾…åŠ©å‡½æ•° ====================

def _run_cmd(args: list[str], timeout: int = 5) -> Optional[str]:
    """å®‰å…¨æ‰§è¡Œå¤–éƒ¨å‘½ä»¤ï¼Œè¿”å› stdout+stderr æˆ– Noneã€‚"""
    try:
        result = subprocess.run(args, capture_output=True, text=True, timeout=timeout)
        return (result.stdout + result.stderr).strip()
    except (FileNotFoundError, subprocess.TimeoutExpired, OSError):
        return None


def _get_ompi_version() -> Optional[str]:
    """è·å– OpenMPI / MPICH ç‰ˆæœ¬å·ã€‚"""
    output = _run_cmd(["mpirun", "--version"])
    if output is None:
        return None
    # OpenMPI: "mpirun (Open MPI) 4.1.5"
    m = re.search(r'Open MPI[)]*\s*(\d+\.\d+\.\d+)', output)
    if m:
        return m.group(1)
    # MPICH fallback
    m = re.search(r'MPICH.*?(\d+\.\d+(?:\.\d+)?)', output)
    if m:
        return f"MPICH {m.group(1)}"
    return None


def _get_nvidia_driver_version() -> Optional[str]:
    """è·å– NVIDIA é©±åŠ¨ç‰ˆæœ¬ã€‚"""
    output = _run_cmd(["nvidia-smi", "--query-gpu=driver_version", "--format=csv,noheader"])
    if output:
        return output.split('\n')[0].strip()
    return None


def _check_item(name: str, func: Callable[[], str]) -> bool:
    """æ‰§è¡Œå•é¡¹æ£€æŸ¥å¹¶æ‰“å°ç»“æœã€‚"""
    try:
        result = func()
        print(f"  âœ… {name}: {result}")
        return True
    except Exception as e:
        print(f"  âŒ {name}: {e}")
        return False


# ==================== æ£€æŸ¥é¡¹ ====================

def check_python() -> Tuple[bool, str]:
    """[1/8] Python ç‰ˆæœ¬ >= 3.8"""
    ver = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
    ok = sys.version_info >= (3, 8)
    return ok, ver


def check_nvidia_driver() -> Tuple[bool, Optional[str]]:
    """[2/8] NVIDIA é©±åŠ¨ >= 530 (CUDA 12.1 è¦æ±‚)"""
    driver_ver = _get_nvidia_driver_version()
    if not driver_ver:
        return False, None
    try:
        major = int(driver_ver.split('.')[0])
        return major >= 525, driver_ver
    except ValueError:
        return True, driver_ver  # æ— æ³•è§£ææ—¶è§†ä¸ºé€šè¿‡


def check_pytorch_cuda() -> Tuple[bool, dict]:
    """[3/8] PyTorch + CUDA 12.1"""
    info: dict = {}
    try:
        import torch
        info["torch_version"] = torch.__version__
        if not torch.cuda.is_available():
            info["error"] = "CUDA ä¸å¯ç”¨ (torch.cuda.is_available() = False)"
            return False, info
        info["cuda_version"] = torch.version.cuda or "unknown"
        info["gpu_count"] = torch.cuda.device_count()
        info["gpus"] = []
        for i in range(min(info["gpu_count"], 8)):
            name = torch.cuda.get_device_name(i)
            mem_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3
            info["gpus"].append(f"{name} ({mem_gb:.1f} GB)")
        return True, info
    except ImportError:
        info["error"] = "PyTorch æœªå®‰è£…"
        return False, info


def check_mpi() -> Tuple[bool, dict]:
    """[4/8] MPI ç¯å¢ƒ (OpenMPI 4.1.5)"""
    info: dict = {}
    mpirun_path = shutil.which("mpirun") or shutil.which("mpiexec")
    info["mpirun"] = mpirun_path
    info["ompi_version"] = _get_ompi_version() if mpirun_path else None

    try:
        from mpi4py import MPI
        info["mpi_standard"] = MPI.Get_version()
        try:
            import mpi4py
            info["mpi4py_version"] = mpi4py.__version__
        except AttributeError:
            pass
        info["mpi4py_ok"] = True
    except ImportError:
        info["mpi4py_ok"] = False

    ok = bool(mpirun_path and info.get("mpi4py_ok"))
    return ok, info


def check_core_deps() -> Tuple[bool, list]:
    """[5/8] æ ¸å¿ƒä¾èµ– (numpy, opt-einsum)"""
    results = []
    all_ok = True
    for pkg, import_name in [("numpy", "numpy"), ("opt-einsum", "opt_einsum")]:
        try:
            mod = __import__(import_name)
            ver = getattr(mod, "__version__", "unknown")
            results.append((pkg, ver, True))
        except ImportError:
            results.append((pkg, None, False))
            all_ok = False
    return all_ok, results


def check_experiment_deps() -> Tuple[bool, list]:
    """[6/8] å®éªŒ/å›¾è¡¨ä¾èµ– (matplotlib, seaborn)"""
    results = []
    all_ok = True
    for pkg, import_name in [("matplotlib", "matplotlib"), ("seaborn", "seaborn")]:
        try:
            mod = __import__(import_name)
            ver = getattr(mod, "__version__", "unknown")
            results.append((pkg, ver, True))
        except ImportError:
            results.append((pkg, None, False))
            all_ok = False
    return all_ok, results


def check_framework_import() -> Tuple[bool, Optional[str]]:
    """[7/8] distributed_gpu æ¡†æ¶å¯¼å…¥"""
    try:
        import distributed_gpu
        ver = distributed_gpu.__version__

        # éªŒè¯æ ¸å¿ƒæ¨¡å—
        from distributed_gpu import (
            MPIManager, TensorDistributor, CostModel,
            GPUManager, PipelineOptimizer, ResourcePlanner, AutoExecutor
        )
        # éªŒè¯ç®—å­æ¨¡å—
        from distributed_gpu.algorithms import (
            distributed_matmul, distributed_conv2d, distributed_fft,
            distributed_einsum, distributed_sum, distributed_stencil_2d
        )
        return True, ver
    except ImportError as e:
        return False, str(e)


# ==================== ä¸»å‡½æ•° ====================

def main() -> int:
    print("=" * 60)
    print("  distributed_gpu ç¯å¢ƒæ£€æµ‹")
    print("  ç›®æ ‡ç¯å¢ƒ: OpenMPI 4.1.5 + CUDA 12.1")
    print("=" * 60)

    passed = 0
    total = 8

    # ---------- [1/8] Python ----------
    print("\n[1/8] Python ç¯å¢ƒ")
    py_ok, py_ver = check_python()
    if py_ok:
        print(f"  âœ… Python ç‰ˆæœ¬: {py_ver}")
        passed += 1
    else:
        print(f"  âŒ Python ç‰ˆæœ¬: {py_ver} (éœ€è¦ >= 3.8)")

    # ---------- [2/8] NVIDIA é©±åŠ¨ ----------
    print("\n[2/8] NVIDIA é©±åŠ¨")
    drv_ok, drv_ver = check_nvidia_driver()
    if drv_ver is None:
        print("  âŒ nvidia-smi ä¸å¯ç”¨ï¼Œè¯·ç¡®è®¤å·²å®‰è£… NVIDIA é©±åŠ¨")
    elif drv_ok:
        print(f"  âœ… NVIDIA é©±åŠ¨ç‰ˆæœ¬: {drv_ver}")
        try:
            major = int(drv_ver.split('.')[0])
            if major >= 530:
                print(f"  âœ… é©±åŠ¨å…¼å®¹ CUDA 12.1 (éœ€è¦ >= 530)")
            else:
                print(f"  âš ï¸  é©±åŠ¨ç‰ˆæœ¬ {drv_ver}ï¼ŒCUDA 12.1 å»ºè®® >= 530")
        except ValueError:
            pass
        passed += 1
    else:
        print(f"  âŒ é©±åŠ¨ç‰ˆæœ¬ {drv_ver} è¿‡ä½ï¼ŒCUDA 12.1 éœ€è¦ >= 530")

    # ---------- [3/8] PyTorch + CUDA ----------
    print("\n[3/8] PyTorch + CUDA 12.1")
    torch_ok, torch_info = check_pytorch_cuda()
    if torch_ok:
        print(f"  âœ… PyTorch ç‰ˆæœ¬: {torch_info['torch_version']}")
        cuda_ver = torch_info["cuda_version"]
        print(f"  âœ… CUDA è¿è¡Œæ—¶ç‰ˆæœ¬: {cuda_ver}")
        if cuda_ver.startswith("12.1"):
            print(f"  âœ… CUDA ç‰ˆæœ¬åŒ¹é…ç›®æ ‡ 12.1")
        elif cuda_ver.startswith("12."):
            print(f"  âš ï¸  CUDA {cuda_ver} (ç›®æ ‡ 12.1ï¼Œå¤§ç‰ˆæœ¬å…¼å®¹)")
        else:
            print(f"  âš ï¸  CUDA {cuda_ver} ä¸ç›®æ ‡ 12.1 ä¸ä¸€è‡´")
            print(f"     å»ºè®®: pip install torch --index-url https://download.pytorch.org/whl/cu121")
        print(f"  âœ… GPU æ•°é‡: {torch_info['gpu_count']}")
        for i, gpu_desc in enumerate(torch_info["gpus"]):
            print(f"     GPU {i}: {gpu_desc}")
        passed += 1
    else:
        if "error" in torch_info:
            print(f"  âŒ {torch_info['error']}")
        if "torch_version" in torch_info:
            print(f"     PyTorch ç‰ˆæœ¬: {torch_info['torch_version']}")
        print(f"     ä¿®å¤: pip install torch --index-url https://download.pytorch.org/whl/cu121")

    # ---------- [4/8] MPI ----------
    print("\n[4/8] MPI ç¯å¢ƒ (ç›®æ ‡: OpenMPI 4.1.5)")
    mpi_ok, mpi_info = check_mpi()
    if mpi_info["mpirun"]:
        print(f"  âœ… MPI è¿è¡Œæ—¶: {mpi_info['mpirun']}")
        ompi_ver = mpi_info.get("ompi_version")
        if ompi_ver:
            print(f"  âœ… MPI ç‰ˆæœ¬: {ompi_ver}")
            if ompi_ver == "4.1.5":
                print(f"  âœ… ç‰ˆæœ¬åŒ¹é…ç›®æ ‡ 4.1.5")
            elif ompi_ver.startswith("4.1."):
                print(f"  âš ï¸  ç‰ˆæœ¬ {ompi_ver} (ç›®æ ‡ 4.1.5ï¼Œå°ç‰ˆæœ¬å…¼å®¹)")
            elif ompi_ver.startswith("4."):
                print(f"  âš ï¸  ç‰ˆæœ¬ {ompi_ver} (ç›®æ ‡ 4.1.5ï¼Œå¤§ç‰ˆæœ¬å…¼å®¹)")
        else:
            print(f"  âš ï¸  æ— æ³•æ£€æµ‹ MPI ç‰ˆæœ¬")
    else:
        print("  âŒ mpirun/mpiexec æœªæ‰¾åˆ°!")
        print("     ä¿®å¤: module load openmpi/4.1.5  (HPC é›†ç¾¤)")
        print("     æˆ–:   conda install -c conda-forge openmpi=4.1.5 -y")

    if mpi_info.get("mpi4py_ok"):
        mpi4py_ver = mpi_info.get("mpi4py_version", "unknown")
        print(f"  âœ… mpi4py: {mpi4py_ver}")
        if mpi_ok:
            passed += 1
    else:
        print("  âŒ mpi4py æœªå®‰è£…!")
        print("     ä¿®å¤: pip install mpi4py")

    # ---------- [5/8] æ ¸å¿ƒä¾èµ– ----------
    print("\n[5/8] æ ¸å¿ƒä¾èµ–")
    deps_ok, deps_list = check_core_deps()
    for pkg, ver, ok in deps_list:
        if ok:
            print(f"  âœ… {pkg}: {ver}")
        else:
            print(f"  âŒ {pkg} æœªå®‰è£…!  ä¿®å¤: pip install {pkg}")
    if deps_ok:
        passed += 1

    # ---------- [6/8] å®éªŒ/å›¾è¡¨ä¾èµ– ----------
    print("\n[6/8] å®éªŒ/å›¾è¡¨ä¾èµ– (å¯é€‰)")
    exp_ok, exp_list = check_experiment_deps()
    for pkg, ver, ok in exp_list:
        if ok:
            print(f"  âœ… {pkg}: {ver}")
        else:
            print(f"  âš ï¸  {pkg} æœªå®‰è£… (è¿è¡Œå®éªŒéœ€è¦)")
            print(f"     ä¿®å¤: pip install -e '.[experiments]'")
    if exp_ok:
        passed += 1
    else:
        print(f"  â„¹ï¸  å®éªŒä¾èµ–ç¼ºå¤±ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œä½†æ— æ³•è¿è¡Œå®éªŒå’Œç”Ÿæˆå›¾è¡¨")
        passed += 1  # å¯é€‰ä¾èµ–ï¼Œä¸é˜»å¡

    # ---------- [7/8] æ¡†æ¶å¯¼å…¥ ----------
    print("\n[7/8] distributed_gpu æ¡†æ¶")
    fw_ok, fw_info = check_framework_import()
    if fw_ok:
        print(f"  âœ… æ¡†æ¶ç‰ˆæœ¬: {fw_info}")
        print(f"  âœ… æ ¸å¿ƒæ¨¡å—: MPIManager, TensorDistributor, CostModel ...")
        print(f"  âœ… ç®—å­æ¨¡å—: matmul, conv2d, fft, einsum, sum, stencil ...")
        passed += 1
    else:
        print(f"  âŒ æ¡†æ¶å¯¼å…¥å¤±è´¥: {fw_info}")
        print("     ä¿®å¤: pip install -e .")

    # ---------- [8/8] MPI å¤šè¿›ç¨‹æµ‹è¯•å»ºè®® ----------
    print("\n[8/8] MPI å¤šè¿›ç¨‹æµ‹è¯•")
    if mpi_ok and torch_ok:
        print("  â„¹ï¸  å•è¿›ç¨‹æ£€æµ‹å·²é€šè¿‡ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯å¤šGPUååŒ:")
        print("     mpirun -n 4 python examples/run_algorithm.py all")
        passed += 1
    else:
        print("  âš ï¸  è¯·å…ˆä¿®å¤ä¸Šè¿°é—®é¢˜åå†æµ‹è¯•å¤šGPUååŒ")

    # ---------- æ€»ç»“ ----------
    print("\n" + "=" * 60)
    if passed == total:
        print(f"  ğŸ‰ å…¨éƒ¨é€šè¿‡ ({passed}/{total})ï¼Œç¯å¢ƒé…ç½®æ­£ç¡®ï¼")
        print(f"     OpenMPI 4.1.5 + CUDA 12.1 ç¯å¢ƒå°±ç»ª")
    else:
        print(f"  âš ï¸  é€šè¿‡ {passed}/{total}ï¼Œè¯·æ ¹æ®ä¸Šæ–¹æç¤ºä¿®å¤é—®é¢˜")
    print("=" * 60)

    return 0 if passed == total else 1


if __name__ == "__main__":
    sys.exit(main())
